{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/home/dhcoe/projects/mlcourse/src'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mdl(X,y):\n",
    "    \n",
    "    scorer=make_scorer(log_loss, greater_is_better=False)\n",
    "\n",
    "    params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "    grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=0, cv=3,n_jobs=-1 ,scoring=scorer)\n",
    "    grid_search_cv.fit(X, y)\n",
    "    NFOLDS=5\n",
    "    skf = StratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    # preds=np.zeros((X_test.shape[0],))\n",
    "    losses=[]\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        # print(X_train.shape,X_val.shape)\n",
    "        clf=grid_search_cv.best_estimator_\n",
    "            \n",
    "        clf.fit(X_train,y_train)\n",
    "        pval=clf.predict_proba(X_val)[:,1]\n",
    "        loss=log_loss(y_val,pval)\n",
    "        losses.append(loss)\n",
    "    print(np.mean(losses))\n",
    "    return np.mean(losses)\n",
    "# evaluate_mdl(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(48842, 16)\n0.31512068804097304\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.31512068804097304"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,QuantileTransformer,PowerTransformer,Normalizer,MaxAbsScaler,KBinsDiscretizer,RobustScaler\n",
    "continuous=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']\n",
    "target=[\"target\"]\n",
    "id=[\"uid\"]\n",
    "categorical=['workclass','marital-status', 'occupation', 'relationship', 'race','sex', 'native-country','education']\n",
    "train=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/train.csv\")\n",
    "test=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/test.csv\")\n",
    "test[\"target\"]=-1\n",
    "\n",
    "\n",
    "data=pd.concat([train,test],ignore_index=True)\n",
    "data[\"workclass\"]=data[\"workclass\"].apply(str.strip).replace(\"?\",np.nan)\n",
    "data[\"workclass\"].fillna(data[\"workclass\"].mode()[0],inplace=True)\n",
    "\n",
    "cnts=data[categorical][\"native-country\"].value_counts()\n",
    "smallcnts=list(cnts[cnts<200].index)\n",
    "data.loc[data[\"native-country\"].isin(smallcnts),\"native-country\"]=\"others\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dummies=pd.get_dummies(data[categorical])\n",
    "dcols=dummies.columns\n",
    "print(data.shape)\n",
    "data=data.merge(dummies,how='left',left_index=True,right_index=True)\n",
    "for col in categorical:\n",
    "    enc=LabelEncoder()\n",
    "    data[col]=enc.fit_transform(data[col].values.reshape(-1,1)).flatten()\n",
    "\n",
    "# data[\"net-cap\"]=data[\"capital-gain\"]-data[\"capital-loss\"]\n",
    "\n",
    "train=data[data[\"target\"]!=-1]\n",
    "test=data[data[\"target\"]==-1]\n",
    "X=train.drop(target+id,axis=1).values\n",
    "y=train.target.values\n",
    "\"both dummy and label + scaling\"\n",
    "evaluate_mdl(X,y)\n",
    "# 0.31566125458576005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' Private'"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "train=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/train.csv\")\n",
    "test=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/test.csv\")\n",
    "test[\"target\"]=-1\n",
    "data=pd.concat([train,test],ignore_index=True)\n",
    "data[\"workclass\"].unique()\n",
    "data[\"workclass\"].mode()[0]"
   ]
  }
 ]
}