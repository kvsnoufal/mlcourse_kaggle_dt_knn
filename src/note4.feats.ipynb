{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(48842, 16)\n(48842, 118)\nFitting 5 folds for each of 294 candidates, totalling 1470 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.3s\n[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    8.3s\n[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   16.1s\n[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   26.9s\n[Parallel(n_jobs=-1)]: Done 1470 out of 1470 | elapsed:   32.7s finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features=None,\n                                              max_leaf_nodes=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              presort='deprecated',\n                                              random_state=42,\n                                              splitter='best'),\n             iid='deprecated', n_jobs=-1,\n             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n                                            31, ...],\n                         'min_samples_split': [2, 3, 4]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=make_scorer(log_loss, greater_is_better=False), verbose=1)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/train.csv\")\n",
    "test=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/test.csv\")\n",
    "test[\"target\"]=-1\n",
    "data=pd.concat([train,test],ignore_index=True)\n",
    "\n",
    "continuous=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']\n",
    "target=[\"target\"]\n",
    "id=[\"uid\"]\n",
    "train.columns\n",
    "categorical=['workclass','marital-status', 'occupation', 'relationship', 'race','sex', 'native-country','education']\n",
    "dummies=pd.get_dummies(data[categorical])\n",
    "dcols=dummies.columns\n",
    "print(data.shape)\n",
    "data=data.merge(dummies,how='left',left_index=True,right_index=True)\n",
    "print(data.shape)\n",
    "train=data[data[\"target\"]!=-1]\n",
    "test=data[data[\"target\"]==-1]\n",
    "len(train),len(test)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "X=train.drop(target+id+categorical,axis=1).values\n",
    "y=train.target.values\n",
    "\n",
    "scorer=make_scorer(log_loss, greater_is_better=False)\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=5,n_jobs=-1 ,scoring=scorer)\n",
    "grid_search_cv.fit(X, y)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    5.2s\n[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   14.5s\n[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:   15.3s finished\n0.32860536226942266\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.32860536226942266"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "def evaluate_mdl(X,y):\n",
    "    \n",
    "    scorer=make_scorer(log_loss, greater_is_better=False)\n",
    "\n",
    "    params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "    grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3,n_jobs=-1 ,scoring=scorer)\n",
    "    grid_search_cv.fit(X, y)\n",
    "    NFOLDS=5\n",
    "    skf = StratifiedKFold(n_splits=NFOLDS)\n",
    "    \n",
    "    preds=np.zeros((X_test.shape[0],))\n",
    "    losses=[]\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        # print(X_train.shape,X_val.shape)\n",
    "        clf=grid_search_cv.best_estimator_\n",
    "            \n",
    "        clf.fit(X_train,y_train)\n",
    "        pval=clf.predict_proba(X_val)[:,1]\n",
    "        loss=log_loss(y_val,pval)\n",
    "        losses.append(loss)\n",
    "    print(np.mean(losses))\n",
    "    return np.mean(losses)\n",
    "evaluate_mdl(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(48842, 16)\nFitting 3 folds for each of 294 candidates, totalling 882 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    5.7s\n[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   16.2s\n[Parallel(n_jobs=-1)]: Done 859 out of 882 | elapsed:   17.0s remaining:    0.5s\n[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:   17.3s finished\n0.3156478721463144\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.3156478721463144"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "continuous=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']\n",
    "target=[\"target\"]\n",
    "id=[\"uid\"]\n",
    "categorical=['workclass','marital-status', 'occupation', 'relationship', 'race','sex', 'native-country','education']\n",
    "train=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/train.csv\")\n",
    "test=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/test.csv\")\n",
    "test[\"target\"]=-1\n",
    "data=pd.concat([train,test],ignore_index=True)\n",
    "dummies=pd.get_dummies(data[categorical])\n",
    "dcols=dummies.columns\n",
    "print(data.shape)\n",
    "data=data.merge(dummies,how='left',left_index=True,right_index=True)\n",
    "for col in categorical:\n",
    "    enc=LabelEncoder()\n",
    "    data[col]=enc.fit_transform(data[col].values.reshape(-1,1)).flatten()\n",
    "train=data[data[\"target\"]!=-1]\n",
    "test=data[data[\"target\"]==-1]\n",
    "X=train.drop(target+id,axis=1).values\n",
    "y=train.target.values\n",
    "\"both dummy and label\"\n",
    "evaluate_mdl(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(48842, 16)\nFitting 3 folds for each of 294 candidates, totalling 882 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    4.7s\n[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   13.5s\n[Parallel(n_jobs=-1)]: Done 859 out of 882 | elapsed:   13.9s remaining:    0.4s\n[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:   14.3s finished\n0.31557310671878147\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.31557310671878147"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,QuantileTransformer,PowerTransformer,Normalizer,MaxAbsScaler,KBinsDiscretizer,RobustScaler\n",
    "continuous=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']\n",
    "target=[\"target\"]\n",
    "id=[\"uid\"]\n",
    "categorical=['workclass','marital-status', 'occupation', 'relationship', 'race','sex', 'native-country','education']\n",
    "train=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/train.csv\")\n",
    "test=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/test.csv\")\n",
    "test[\"target\"]=-1\n",
    "data=pd.concat([train,test],ignore_index=True)\n",
    "cnts=data[categorical][\"native-country\"].value_counts()\n",
    "smallcnts=list(cnts[cnts<100].index)\n",
    "data.loc[data[\"native-country\"].isin(smallcnts),\"native-country\"]=\"others\"\n",
    "dummies=pd.get_dummies(data[categorical])\n",
    "dcols=dummies.columns\n",
    "print(data.shape)\n",
    "data=data.merge(dummies,how='left',left_index=True,right_index=True)\n",
    "for col in categorical:\n",
    "    enc=LabelEncoder()\n",
    "    data[col]=enc.fit_transform(data[col].values.reshape(-1,1)).flatten()\n",
    "\n",
    "data[\"net-cap\"]=data[\"capital-gain\"]-data[\"capital-loss\"]\n",
    "\n",
    "# for col in continuous:\n",
    "#     sc= StandardScaler()\n",
    "#     data[col]=sc.fit_transform(data[col].values.reshape(-1,1)).flatten()\n",
    "train=data[data[\"target\"]!=-1]\n",
    "test=data[data[\"target\"]==-1]\n",
    "X=train.drop(target+id,axis=1).values\n",
    "y=train.target.values\n",
    "\"both dummy and label + scaling\"\n",
    "evaluate_mdl(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "workclass 9\nmarital-status 7\noccupation 15\nrelationship 6\nrace 5\nsex 2\nnative-country 17\neducation 16\n"
    }
   ],
   "source": [
    "for c in categorical:\n",
    "    print(c,data[c].nunique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index([' United-States', ' Mexico', ' ?', ' Philippines', ' Germany',\n       ' Puerto-Rico', ' Canada', ' El-Salvador', ' India', ' Cuba',\n       ' England', ' China', ' South', ' Jamaica', ' Italy',\n       ' Dominican-Republic', ' Japan', ' Guatemala', ' Poland', ' Vietnam',\n       ' Columbia', ' Haiti', ' Portugal', ' Taiwan', ' Iran', ' Greece',\n       ' Nicaragua', ' Peru', ' Ecuador', ' France', ' Ireland', ' Thailand',\n       ' Hong', ' Cambodia', ' Trinadad&Tobago', ' Yugoslavia',\n       ' Outlying-US(Guam-USVI-etc)', ' Laos', ' Scotland', ' Honduras',\n       ' Hungary', ' Holand-Netherlands'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "train=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/train.csv\")\n",
    "test=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/test.csv\")\n",
    "test[\"target\"]=-1\n",
    "data=pd.concat([train,test],ignore_index=True)\n",
    "data[\"marital-status\"].value_counts()\n",
    "data[\"native-country\"].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(48842, 16)\nFitting 3 folds for each of 294 candidates, totalling 882 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    5.2s\n[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   14.6s\n[Parallel(n_jobs=-1)]: Done 859 out of 882 | elapsed:   15.2s remaining:    0.4s\n[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:   15.5s finished\n0.3173811870523929\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.3173811870523929"
     },
     "metadata": {},
     "execution_count": 226
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,QuantileTransformer,PowerTransformer,Normalizer,MaxAbsScaler,KBinsDiscretizer,RobustScaler\n",
    "continuous=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']\n",
    "target=[\"target\"]\n",
    "id=[\"uid\"]\n",
    "categorical=['workclass','marital-status', 'occupation', 'relationship', 'race','sex', 'native-country','education']\n",
    "train=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/train.csv\")\n",
    "test=pd.read_csv(\"../input/ods-mlclass-dubai-2019-03-lecture3-hw/test.csv\")\n",
    "test[\"target\"]=-1\n",
    "data=pd.concat([train,test],ignore_index=True)\n",
    "cnts=data[categorical][\"native-country\"].value_counts()\n",
    "smallcnts=list(cnts[cnts<100].index)\n",
    "data.loc[data[\"native-country\"].isin(smallcnts),\"native-country\"]=\"others\"\n",
    "dummies=pd.get_dummies(data[categorical])\n",
    "dcols=dummies.columns\n",
    "print(data.shape)\n",
    "data=data.merge(dummies,how='left',left_index=True,right_index=True)\n",
    "for col in categorical:\n",
    "    enc=LabelEncoder()\n",
    "    data[col]=enc.fit_transform(data[col].values.reshape(-1,1)).flatten()\n",
    "\n",
    "\n",
    "data[\"net-cap\"]=data[\"capital-gain\"]-data[\"capital-loss\"]\n",
    "# for col in continuous:\n",
    "#     data[col]=(data[col].values/100).round()\n",
    "\n",
    "# for col in continuous:\n",
    "#     sc= StandardScaler()\n",
    "#     data[col]=sc.fit_transform(data[col].values.reshape(-1,1)).flatten()\n",
    "train=data[data[\"target\"]!=-1]\n",
    "test=data[data[\"target\"]==-1]\n",
    "X=train.drop(target,axis=1).values\n",
    "y=train.target.values\n",
    "\"both dummy and label + scaling\"\n",
    "evaluate_mdl(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 1764 candidates, totalling 5292 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    3.4s\n[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:    9.8s\n[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   20.1s\n[Parallel(n_jobs=-1)]: Done 2428 tasks      | elapsed:   34.0s\n[Parallel(n_jobs=-1)]: Done 3528 tasks      | elapsed:   51.9s\n[Parallel(n_jobs=-1)]: Done 4828 tasks      | elapsed:  1.2min\n[Parallel(n_jobs=-1)]: Done 5292 out of 5292 | elapsed:  1.4min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=None, max_features=None, max_leaf_nodes=63,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=10, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=42, splitter='best')"
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "source": [
    "\n",
    "scorer=make_scorer(log_loss, greater_is_better=False)\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4],\\\n",
    "'min_samples_leaf':[1, 5, 10, 20, 50, 100]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3,n_jobs=-1 ,scoring=scorer)\n",
    "grid_search_cv.fit(X, y)\n",
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.31330859367867764\nCPU times: user 889 ms, sys: 0 ns, total: 889 ms\nWall time: 888 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "NFOLDS=5\n",
    "skf = StratifiedKFold(n_splits=NFOLDS)\n",
    "\n",
    "\n",
    "X_test=test.drop(id+target,axis=1).values\n",
    "preds=np.zeros((X_test.shape[0],))\n",
    "losses=[]\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    # print(X_train.shape,X_val.shape)\n",
    "    clf=grid_search_cv.best_estimator_\n",
    "        \n",
    "    clf.fit(X_train,y_train)\n",
    "    pval=clf.predict_proba(X_val)[:,1]\n",
    "    loss=log_loss(y_val,pval)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    pred_test=clf.predict_proba(X_test)[:,1]\n",
    "    preds+=pred_test\n",
    "print(np.mean(losses))\n",
    "preds=preds/NFOLDS\n",
    "sub=pd.DataFrame()\n",
    "sub[\"uid\"]=test.reset_index()[\"uid\"]\n",
    "\n",
    "sub[\"target\"]= preds\n",
    "sub.head()\n",
    "sub.to_csv(\"submit_hyp_opt1.csv\",index=None)"
   ]
  }
 ]
}